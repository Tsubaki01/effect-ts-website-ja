---
title: オペレーション
excerpt: このセクションでは、tapping、要素の取得、非同期イテラブルの代替としてのストリームの探索、mapping、filtering、scanning、draining、変化の検出、zipping、grouping、連結、merging、interleaving、interspersing、broadcasting、buffering、debouncingなど、重要なストリーム操作を探ります。
bottomNavigation: pagination
---

このセクションでは、ストリームに対して実行できるいくつかの重要な操作を探ります。これらの操作により、ストリーム要素をさまざまな方法で操作および対話することができます。

## Tapping

Tappingは、ストリームの各エミッションに対してエフェクトを実行する操作です。これにより、各要素を観察し、エフェクトフルな操作を実行し、この観察の結果を破棄することができます。重要なことに、`Stream.tap`操作はストリームの要素を変更せず、ストリームの戻り値の型にも影響を与えません。

例えば、`Stream.tap`を使用してストリームの各要素を印刷することができます：

```ts twoslash
import { Stream, Console, Effect } from "effect"

const stream = Stream.make(1, 2, 3).pipe(
  Stream.tap((n) => Console.log(`before mapping: ${n}`)),
  Stream.map((n) => n * 2),
  Stream.tap((n) => Console.log(`after mapping: ${n}`))
)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
before mapping: 1
after mapping: 2
before mapping: 2
after mapping: 4
before mapping: 3
after mapping: 6
{ _id: 'Chunk', values: [ 2, 4, 6 ] }
*/
```

## 要素の取得

もう一つの重要な操作は要素の取得で、これによりストリームから特定の数の要素を抽出することができます。これを達成するためのいくつかの方法は次の通りです：

- `take`。固定数の要素を抽出する。
- `takeWhile`。特定の条件が満たされるまで要素を抽出する。
- `takeUntil`。特定の条件が満たされるまで要素を抽出する。
- `takeRight`。末尾から指定された数の要素を抽出する。

```ts twoslash
import { Stream, Effect } from "effect"

const stream = Stream.iterate(0, (n) => n + 1)

// `take`を使用して固定数の要素を抽出する：
const s1 = Stream.take(stream, 5)
Effect.runPromise(Stream.runCollect(s1)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ 0, 1, 2, 3, 4 ] }
*/

// `takeWhile`を使用して特定の条件が満たされるまで要素を抽出する：
const s2 = Stream.takeWhile(stream, (n) => n < 5)
Effect.runPromise(Stream.runCollect(s2)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ 0, 1, 2, 3, 4 ] }
*/

// 特定の条件が満たされるまで要素を抽出するために `takeUntil` を使用する：
const s3 = Stream.takeUntil(stream, (n) => n === 5)
Effect.runPromise(Stream.runCollect(s3)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ 0, 1, 2, 3, 4, 5 ] }
*/

// `takeRight`を使用して末尾から指定された数の要素を抽出する：
const s4 = Stream.takeRight(s3, 3)
Effect.runPromise(Stream.runCollect(s4)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ 3, 4, 5 ] }
*/
```

### Async Iterablesの代替としてのStreamsの探求

非同期データソース（例えば、async iterables）を扱う際、特定の条件が満たされるまでループでデータを消費する必要がよくあります。このチュートリアルでは、Streamsを使用して同様の動作を初心者向けに実現する方法を紹介します。

async iterablesでは、breakやreturnステートメントに遭遇するまでデータ消費がループで続行されます。この動作をStreamsで再現するには、いくつかのオプションがあります：

1. **Stream.takeUntil:** この関数は、指定された条件がtrueと評価されるまでストリームから要素を取り出すことができます。これは、特定の条件が満たされたときにasync iterablesのループを抜けるのに似ています。

2. **Stream.toPull:** `Stream.toPull`関数は、async iterablesをループする動作を再現するもう一つの方法です。これは、ストリームからデータチャンクを繰り返し引き出すエフェクトを返します。このエフェクトは、ストリームが終了したときに`None`で失敗するか、失敗した場合に`Some`エラーで失敗することがあります。

次に、2番目のオプションである`Stream.toPull`を詳しく見てみましょう。

```ts twoslash
import { Stream, Effect } from "effect"

// チャンク化されたストリームをシミュレートする
const stream = Stream.fromIterable([1, 2, 3, 4, 5]).pipe(Stream.rechunk(2))

const program = Effect.gen(function* () {
  // ストリームからデータチャンクを取得するエフェクトを作成する
  const getChunk = yield* Stream.toPull(stream)

  // チャンクを継続的に取得して処理する
  while (true) {
    const chunk = yield* getChunk
    console.log(chunk)
  }
})

Effect.runPromise(Effect.scoped(program)).then(console.log, console.error)
/*
出力:
{ _id: 'Chunk', values: [ 1, 2 ] }
{ _id: 'Chunk', values: [ 3, 4 ] }
{ _id: 'Chunk', values: [ 5 ] }
(FiberFailure) Error: {
  "_id": "Option",
  "_tag": "None"
}
*/
```

この例では、`Stream.toPull`を使用して`stream`からデータチャンクを繰り返し取得しています。コードはループに入り、処理するデータがなくなるまでチャンクを取得して表示し続けます。

## マッピング

このセクションでは、`Stream.map`ファミリーの操作を使用してストリーム内の要素をどのように変換するかを探ります。これらの操作により、ストリームの各要素に関数を適用し、変換された値を持つ新しいストリームを生成することができます。

### 基本的なマッピング

`Stream.map`操作は、指定された関数をストリームのすべての要素に適用し、変換された値を持つ別のストリームを作成します。例を使って説明しましょう：

```ts twoslash
import { Stream, Effect } from "effect"

const stream = Stream.make(1, 2, 3).pipe(Stream.map((n) => n + 1))

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ 2, 3, 4 ] }
*/
```

### エフェクトフルマッピング

変換にエフェクトが関わる場合は、代わりに`Stream.mapEffect`を使用できます。これにより、ストリームの各要素にエフェクトを伴う関数を適用し、エフェクトの結果を持つ新しいストリームを生成することができます。

```ts twoslash
import { Stream, Random, Effect } from "effect"

const stream = Stream.make(10, 20, 30).pipe(
  Stream.mapEffect((n) => Random.nextIntBetween(0, n))
)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
Example 出力:
{ _id: 'Chunk', values: [ 5, 9, 22 ] }
*/
```

エフェクトを並行して評価するには、`concurrency`オプションを使用できます。これにより、並行して実行されるエフェクトの数を指定できます。結果は元の順序で下流に送信されます。

URLを並行して取得するシンプルなページダウンローダーを書いてみましょう：

```ts twoslash
import { Stream, Effect } from "effect"

const getUrls = Effect.succeed(["url0", "url1", "url2"])

const fetchUrl = (url: string) =>
  Effect.succeed([
    `Resource 0-${url}`,
    `Resource 1-${url}`,
    `Resource 2-${url}`
  ])

const stream = Stream.fromIterableEffect(getUrls).pipe(
  Stream.mapEffect(fetchUrl, { concurrency: 4 })
)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{
  _id: 'Chunk',
  values: [
    [ 'Resource 0-url0', 'Resource 1-url0', 'Resource 2-url0' ],
    [ 'Resource 0-url1', 'Resource 1-url1', 'Resource 2-url1' ],
    [ 'Resource 0-url2', 'Resource 1-url2', 'Resource 2-url2' ]
  ]
}
*/
```

### 状態を持つマッピング

`Stream.mapAccum`操作は`Stream.map`に似ていますが、要素を状態を持って変換し、1つの操作でマッピングと蓄積を行うことができます。入力ストリームの累積合計を計算する方法を見てみましょう：

```ts twoslash
import { Stream, Effect } from "effect"

const runningTotal = (stream: Stream.Stream<number>): Stream.Stream<number> =>
  stream.pipe(Stream.mapAccum(0, (s, a) => [s + a, s + a]))

Effect.runPromise(Stream.runCollect(runningTotal(Stream.range(0, 5)))).then(
  console.log
)
/*
出力:
{ _id: 'Chunk', values: [ 0, 1, 3, 6, 10, 15 ] }
*/
```

### マッピングとフラット化

`Stream.mapConcat`操作は`Stream.map`に似ていますが、さらに一歩進んでいます。各要素を0個以上の`Iterable`型の要素にマッピングし、その後ストリーム全体をフラット化します。例を使って説明しましょう：

```ts twoslash
import { Stream, Effect } from "effect"

const numbers = Stream.make("1-2-3", "4-5", "6").pipe(
  Stream.mapConcat((s) => s.split("-")),
  Stream.map((s) => parseInt(s))
)

Effect.runPromise(Stream.runCollect(numbers)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ 1, 2, 3, 4, 5, 6 ] }
*/
```

この例では、`"1-2-3"`のような文字列のストリームを取り、それらを個々の数字に分割し、整数のフラット化されたストリームを生成します。

### 定数値へのマッピング

`Stream.as`メソッドは、ストリームの成功値を指定された定数値にマッピングすることを可能にします。これは、要素を一様な値に変換したい場合に便利です。ここでは、すべての要素を`null`値にマッピングする例を示します：

```ts twoslash
import { Stream, Effect } from "effect"

const stream = Stream.range(1, 5).pipe(Stream.as(null))

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ null, null, null, null, null ] }
*/
```

この場合、ストリームの元の値に関係なく、すべてを`null`にマッピングしました。

## フィルタリング

`Stream.filter`操作は、指定された条件を満たす要素を通過させるふるいのようなものです。ストリームをふるいにかけ、与えられた基準を満たす要素だけを保持する方法と考えてください。例を示します：

```ts twoslash
import { Stream, Effect } from "effect"

const stream = Stream.range(1, 11).pipe(Stream.filter((n) => n % 2 === 0))

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ 2, 4, 6, 8, 10 ] }
*/
```

この例では、1から10までの数字のストリームを開始し、`Stream.filter`を使用して偶数（条件 `n % 2 === 0` を満たすもの）だけを保持します。結果は、元のストリームから偶数を含むフィルタリングされたストリームです。

## スキャン

このセクションでは、ストリームスキャンの概念を探ります。スキャンはフォールドに似ていますが、履歴的な視点を提供します。フォールドと同様に、スキャンも二項演算子と初期値を含みます。しかし、スキャンのユニークな点は、ストリームの一部としてすべての中間結果を出力することです。

```ts twoslash
import { Stream, Effect } from "effect"

const stream = Stream.range(1, 5).pipe(Stream.scan(0, (a, b) => a + b))

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ 0, 1, 3, 6, 10, 15 ] }
*/
```

この例では、1から5までの数字のストリームがあり、初期値0から始めて累積加算を行うために`Stream.scan`を使用します。結果は、各ステップで累積和を出力するストリームです：0、1、3、6、10、15。

Stream.scanは、ストリーム変換の履歴を保持する方法を提供し、さまざまなアプリケーションで非常に貴重です。

さらに、スキャンの最終結果だけが必要な場合は、`Stream.runFold`を使用できます。

```ts twoslash
import { Stream, Effect } from "effect"

const fold = Stream.range(1, 5).pipe(Stream.runFold(0, (a, b) => a + b))

Effect.runPromise(fold).then(console.log) // 出力: 15
```

この場合、`Stream.runFold`は最終的な累積値を返します。この例では15です。

## ドレイン

このセクションでは、ストリームドレインの概念を探ります。エフェクトフルな操作で満たされたストリームがあると想像してください。しかし、生成される値には興味がなく、これらのエフェクトを実行して結果を破棄したい場合があります。ここで`Stream.drain`関数が役立ちます。

いくつかの例を見てみましょう：

**例1: 値の破棄**

```ts twoslash
import { Stream, Effect } from "effect"

// ストリームを作成し、すぐにドレインします。
const s1 = Stream.range(1, 5).pipe(Stream.drain)

Effect.runPromise(Stream.runCollect(s1)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [] }
*/
```

この例では、1から5までの値を持つストリームがありますが、`Stream.drain`を使用してこれらの値を破棄します。その結果、出力ストリームは空になります。

**例2: ランダムエフェクトの実行**

```ts twoslash
import { Stream, Effect, Random } from "effect"

const s2 = Stream.repeatEffect(
  Effect.gen(function* () {
    const nextInt = yield* Random.nextInt
    const number = Math.abs(nextInt % 10)
    console.log(`random number: ${number}`)
    return number
  })
).pipe(Stream.take(3))

Effect.runPromise(Stream.runCollect(s2)).then(console.log)
/*
出力の例:
random number: 7
random number: 5
random number: 0
{ _id: 'Chunk', values: [ 7, 5, 0 ] }
*/

const s3 = Stream.drain(s2)

Effect.runPromise(Stream.runCollect(s3)).then(console.log)
/*
Example 出力:
random number: 0
random number: 1
random number: 7
{ _id: 'Chunk', values: [] }
*/
```

この例では、ランダムエフェクトを持つストリームを作成し、最初にこれらのエフェクトの値を収集します。後で、`Stream.drain`を使用して値を収集せずに同じエフェクトを実行します。これにより、発行された値に興味がない場合に、drainingを使用して効果的な操作をトリガーする方法を示します。

Stream drainingは、アプリケーション内で特定のアクションやクリーンアップタスクをメインのデータストリームに影響を与えずに実行する必要がある場合に特に役立ちます。

## ストリーム内の変更を検出する

このセクションでは、`Stream.changes`操作を探ります。これにより、ストリーム内の前の要素と異なる要素を検出して発行することができます。

```ts twoslash
import { Stream, Effect } from "effect"

const stream = Stream.make(1, 1, 1, 2, 2, 3, 4).pipe(Stream.changes)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ 1, 2, 3, 4 ] }
*/
```

## Zipping

Zippingは、2つ以上のストリームを組み合わせて、入力ストリームの要素をペアにして新しいストリームを作成するプロセスです。これを実現するために、`Stream.zip`および`Stream.zipWith`オペレーターを使用できます。いくつかの例を見てみましょう：

```ts twoslash
import { Stream, Effect } from "effect"

// 2つのストリームを作成し、それらをzipします。
const s1 = Stream.zip(
  Stream.make(1, 2, 3, 4, 5, 6),
  Stream.make("a", "b", "c")
)

Effect.runPromise(Stream.runCollect(s1)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ [ 1, 'a' ], [ 2, 'b' ], [ 3, 'c' ] ] }
*/

// 2つのストリームを作成し、カスタムロジックでzipします。
const s2 = Stream.zipWith(
  Stream.make(1, 2, 3, 4, 5, 6),
  Stream.make("a", "b", "c"),
  (n, s) => [n - s.length, s]
)

Effect.runPromise(Stream.runCollect(s2)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ [ 0, 'a' ], [ 1, 'b' ], [ 2, 'c' ] ] }
*/
```

新しいストリームは、いずれかのストリームが終了すると終了します。

### ストリームの終了処理

入力ストリームの一方が他方より先に終了する場合、デフォルト値でzipする必要があるかもしれません。`Stream.zipAll`および`Stream.zipAllWith`操作を使用すると、両方のストリームに対してデフォルト値を指定してこのようなシナリオに対処できます。例を見てみましょう：

```ts twoslash
import { Stream, Effect } from "effect"

const s1 = Stream.zipAll(Stream.make(1, 2, 3, 4, 5, 6), {
  other: Stream.make("a", "b", "c"),
  defaultSelf: 0,
  defaultOther: "x"
})

Effect.runPromise(Stream.runCollect(s1)).then(console.log)
/*
出力:
{
  _id: 'Chunk',
  values: [
    [ 1, 'a' ],
    [ 2, 'b' ],
    [ 3, 'c' ],
    [ 4, 'x' ],
    [ 5, 'x' ],
    [ 6, 'x' ]
  ]
}
*/

const s2 = Stream.zipAllWith(Stream.make(1, 2, 3, 4, 5, 6), {
  other: Stream.make("a", "b", "c"),
  onSelf: (n) => [n, "x"],
  onOther: (s) => [0, s],
  onBoth: (n, s) => [n - s.length, s]
})

Effect.runPromise(Stream.runCollect(s2)).then(console.log)
/*
出力:
{
  _id: 'Chunk',
  values: [
    [ 0, 'a' ],
    [ 1, 'b' ],
    [ 2, 'c' ],
    [ 4, 'x' ],
    [ 5, 'x' ],
    [ 6, 'x' ]
  ]
}
*/
```

これにより、一方のストリームが他方より先に完了した場合のzip処理を扱うことができます。

### 異なる速度でストリームをジップする

時々、異なる速度で要素を生成する2つのストリームを持つことがあります。要素をジップする際に遅い方を待ちたくない場合は、`Stream.zipLatest`または`Stream.zipLatestWith`を使用できます。これらの操作は、どちらかのストリームから値が発行されると、その値を他方のストリームの最新の値と組み合わせて結果を生成します。例を見てみましょう：

```ts twoslash
import { Stream, Schedule, Effect } from "effect"

const s1 = Stream.make(1, 2, 3).pipe(
  Stream.schedule(Schedule.spaced("1 second"))
)

const s2 = Stream.make("a", "b", "c", "d").pipe(
  Stream.schedule(Schedule.spaced("500 millis"))
)

const stream = Stream.zipLatest(s1, s2)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{
  _id: 'Chunk',
  values: [
    [ 1, 'a' ],
    [ 1, 'b' ],
    [ 2, 'b' ],
    [ 2, 'c' ],
    [ 2, 'd' ],
    [ 3, 'd' ]
  ]
}
*/
```

ここで、`Stream.zipLatest`は遅い方を待たずに両方のストリームから要素を結合し、より応答性の高い出力を生成します。

### 前後の要素とのペアリング

- `zipWithPrevious`: このオペレーターはストリームの各要素をその前の要素とペアにします。

- `zipWithNext`: これはストリームの各要素をその次の要素とペアにします。

- `zipWithPreviousAndNext`: このオペレーターは各要素をその前後の要素とペアにします。

これらの操作を示す例を見てみましょう：

```ts twoslash
import { Stream, Effect } from "effect"

const stream = Stream.make(1, 2, 3, 4)

const s1 = Stream.zipWithPrevious(stream)

const s2 = Stream.zipWithNext(stream)

const s3 = Stream.zipWithPreviousAndNext(stream)

Effect.runPromise(Stream.runCollect(s1)).then((chunks) =>
  console.log("%o", chunks)
)
/*
出力:
{
  _id: 'Chunk',
  values: [
    [ { _id: 'Option', _tag: 'None' }, 1, [length]: 2 ],
    [ { _id: 'Option', _tag: 'Some', value: 1 }, 2, [length]: 2 ],
    [ { _id: 'Option', _tag: 'Some', value: 2 }, 3, [length]: 2 ],
    [ { _id: 'Option', _tag: 'Some', value: 3 }, 4, [length]: 2 ],
    [length]: 4
  ]
}
*/

Effect.runPromise(Stream.runCollect(s2)).then((chunks) =>
  console.log("%o", chunks)
)
/*
出力:
{
  _id: 'Chunk',
  values: [
    [ 1, { _id: 'Option', _tag: 'Some', value: 2 }, [length]: 2 ],
    [ 2, { _id: 'Option', _tag: 'Some', value: 3 }, [length]: 2 ],
    [ 3, { _id: 'Option', _tag: 'Some', value: 4 }, [length]: 2 ],
    [ 4, { _id: 'Option', _tag: 'None' }, [length]: 2 ],
    [length]: 4
  ]
}
*/

Effect.runPromise(Stream.runCollect(s3)).then((chunks) =>
  console.log("%o", chunks)
)
/*
出力:
{
  _id: 'Chunk',
  values: [
    [
      { _id: 'Option', _tag: 'None' },
      1,
      { _id: 'Option', _tag: 'Some', value: 2 },
      [length]: 3
    ],
    [
      { _id: 'Option', _tag: 'Some', value: 1 },
      2,
      { _id: 'Option', _tag: 'Some', value: 3 },
      [length]: 3
    ],
    [
      { _id: 'Option', _tag: 'Some', value: 2 },
      3,
      { _id: 'Option', _tag: 'Some', value: 4 },
      [length]: 3
    ],
    [
      { _id: 'Option', _tag: 'Some', value: 3 },
      4,
      { _id: 'Option', _tag: 'None' },
      [length]: 3
    ],
    [length]: 4
  ]
}
*/
```

### ストリーム要素のインデックス付け

便利なオペレーターの一つに`Stream.zipWithIndex`があります。これはストリームの各要素にそのインデックスをペアリングしてインデックスを付けます。ストリーム内の要素の位置を把握する必要がある場合に特に役立ちます。

以下はストリーム内の要素にインデックスを付ける例です：

```ts twoslash
import { Stream, Effect } from "effect"

const stream = Stream.make("Mary", "James", "Robert", "Patricia")

const indexedStream = Stream.zipWithIndex(stream)

Effect.runPromise(Stream.runCollect(indexedStream)).then(console.log)
/*
出力:
{
  _id: 'Chunk',
  values: [ [ 'Mary', 0 ], [ 'James', 1 ], [ 'Robert', 2 ], [ 'Patricia', 3 ] ]
}
*/
```

## ストリームの直積

Streamモジュールは強力な機能を導入しています。それは、2つのストリームの直積を計算する能力です。この操作により、2つの別々のストリームから要素の組み合わせを生成することができます。この概念をさらに探ってみましょう。

2つのアイテムのセットがあり、それぞれのセットから1つのアイテムを取り出してすべての可能なペアを生成したいとします。このプロセスは、セットの直積を見つけることとして知られています。ストリームの文脈では、2つのストリームから要素の組み合わせを作成することを意味します。

これを達成するために、Streamモジュールは`Stream.cross`オペレーターとそのバリアントを提供しています。これらのオペレーターは2つのストリームを取り、元のストリームのすべての可能な組み合わせを含む新しいストリームを生成します。

ここに実際の例があります：

```ts twoslash
import { Stream, Effect } from "effect"

const s1 = Stream.make(1, 2, 3)
const s2 = Stream.make("a", "b")

const product = Stream.cross(s1, s2)

Effect.runPromise(Stream.runCollect(product)).then(console.log)
/*
出力:
{
  _id: 'Chunk',
  values: [
    [ 1, 'a' ],
    [ 1, 'b' ],
    [ 2, 'a' ],
    [ 2, 'b' ],
    [ 3, 'a' ],
    [ 3, 'b' ]
  ]
}
*/
```

右側のストリーム（この場合は`s2`）は、左側のストリーム（`s1`）の各要素に対して複数回反復されることに注意してください。つまり、右側のストリームが高価な操作や副作用のある操作を含む場合、それらは複数回実行されることになります。

## パーティショニング

ストリームのパーティショニングとは、指定された条件に基づいてストリームを2つの別々のストリームに分割することを意味します。Streamモジュールはこれを達成するための便利な関数を2つ提供しています：`Stream.partition`と`Stream.partitionEither`です。これらの関数がどのように機能し、いつ使用するかを見てみましょう。

### partition

`Stream.partition`関数は述語を入力として受け取り、元のストリームを2つのサブストリームに分割します：述語を満たす要素（`true`と評価される）を含むストリームと、述語を満たさない要素（`false`と評価される）を含むストリームです。さらに、これらのサブストリームは`Scope`型でラップされています。

ここに、数値のストリームを偶数と奇数に分割する例があります：

```ts twoslash
import { Stream, Effect } from "effect"

const partition = Stream.range(1, 9).pipe(
  Stream.partition((n) => n % 2 === 0, { bufferSize: 5 })
)

Effect.runPromise(
  Effect.scoped(
    Effect.gen(function* () {
      const [evens, odds] = yield* partition
      console.log(yield* Stream.runCollect(evens))
      console.log(yield* Stream.runCollect(odds))
    })
  )
)
/*
出力:
{ _id: 'Chunk', values: [ 2, 4, 6, 8 ] }
{ _id: 'Chunk', values: [ 1, 3, 5, 7, 9 ] }
*/
```

この例では、述語を使用してストリームを偶数と奇数に分割するために `Stream.partition` 関数を使用しています。`bufferSize` オプションは、速いストリームが遅いストリームをどれだけ先行できるかを制御します。

### partitionEither

場合によっては、効果的な述語を使用してストリームを分割する必要があるかもしれません。そのような場合には、`Stream.partitionEither` 関数が利用できます。この関数は効果的な述語を受け取り、その結果に基づいてストリームを2つのサブストリームに分割します：`Either.left` の値を生成する要素は一方のサブストリームに、`Either.right` の値を生成する要素はもう一方のサブストリームに分けられます。

ここでは、効果的な条件に基づいて数値のストリームを分割するために `Stream.partitionEither` を使用する例を示します：

```ts twoslash
import { Stream, Effect, Either } from "effect"

const partition = Stream.range(1, 9).pipe(
  Stream.partitionEither(
    (n) => Effect.succeed(n % 2 === 0 ? Either.left(n) : Either.right(n)),
    { bufferSize: 5 }
  )
)

Effect.runPromise(
  Effect.scoped(
    Effect.gen(function* () {
      const [evens, odds] = yield* partition
      console.log(yield* Stream.runCollect(evens))
      console.log(yield* Stream.runCollect(odds))
    })
  )
)
/*
出力:
{ _id: 'Chunk', values: [ 2, 4, 6, 8 ] }
{ _id: 'Chunk', values: [ 1, 3, 5, 7, 9 ] }
*/
```

この場合、`Stream.partitionEither` 関数はストリームを2つのサブストリームに分割します。一方は5未満の値（`Either.left` を使用して2倍にする）を含み、もう一方は5以上の値（`Either.right` を使用）を含みます。

## GroupBy

データのストリームを扱う際には、特定の基準に基づいて要素をグループ化する必要があることがよくあります。Streamモジュールはこれを達成するための2つの関数、`groupByKey` と `groupBy` を提供しています。これらの関数がどのように機能し、いつ使用するかを見てみましょう。

### groupByKey

`Stream.groupByKey` 関数は、型 `(a: A) => K` の単純な関数によってストリームを分割することを可能にします。ここで、`A` はストリーム内の要素の型を表し、`K` はストリームを分割するためのキーを表します。
この関数は効果的ではなく、提供された関数を適用することで単純に要素をグループ化します。

`Stream.groupByKey` 関数は `GroupBy` と呼ばれる新しいデータ型を返します。
この `GroupBy` 型はグループ化されたストリームを表します。
グループを操作するには、`GroupBy.evaluate` 関数を使用できます。この関数は型 `(key: K, stream: Stream<V, E>) => Stream.Stream<...>` の関数を受け取り、すべてのグループに対して実行され、非決定的な方法でそれらをマージします。

以下の例では、`groupByKey` を使用して試験結果を得点の十の位でグループ化し、各グループの結果の数をカウントします：

```ts twoslash
import { Stream, GroupBy, Effect, Chunk } from "effect"

class Exam {
  constructor(
    readonly person: string,
    readonly score: number
  ) {}
}

const examResults = [
  new Exam("Alex", 64),
  new Exam("Michael", 97),
  new Exam("Bill", 77),
  new Exam("John", 78),
  new Exam("Bobby", 71)
]

const groupByKeyResult = Stream.fromIterable(examResults).pipe(
  Stream.groupByKey((exam) => Math.floor(exam.score / 10) * 10)
)

const stream = GroupBy.evaluate(groupByKeyResult, (key, stream) =>
  Stream.fromEffect(
    Stream.runCollect(stream).pipe(
      Effect.andThen((chunk) => [key, Chunk.size(chunk)] as const)
    )
  )
)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ [ 60, 1 ], [ 90, 1 ], [ 70, 3 ] ] }
*/
```

この例では、試験結果を得点の十の位（例：60、90、70）でグループ化します。`groupByKey` 関数は、シンプルで副作用のないグループ化に最適です。

### groupBy

副作用を伴うグループ化が必要なより複雑なシナリオでは、`Stream.groupBy` 関数を使用できます。この関数は副作用のあるグループ化関数を受け取り、グループ化されたストリームを表す `GroupBy` データ型を生成します。その後、以前と同様に `GroupBy.evaluate` を使用してグループを処理できます。

次の例では、名前を最初の文字でグループ化し、各グループの名前の数をカウントします。なお、グループ化操作自体は副作用があるものとしてシミュレートされています。

```ts twoslash
import { Stream, GroupBy, Effect, Chunk } from "effect"

const groupByKeyResult = Stream.fromIterable([
  "Mary",
  "James",
  "Robert",
  "Patricia",
  "John",
  "Jennifer",
  "Rebecca",
  "Peter"
]).pipe(
  Stream.groupBy((name) => Effect.succeed([name.substring(0, 1), name]))
)

const stream = GroupBy.evaluate(groupByKeyResult, (key, stream) =>
  Stream.fromEffect(
    Stream.runCollect(stream).pipe(
      Effect.andThen((chunk) => [key, Chunk.size(chunk)] as const)
    )
  )
)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{
  _id: 'Chunk',
  values: [ [ 'M', 1 ], [ 'J', 3 ], [ 'R', 2 ], [ 'P', 2 ] ]
}
*/
```

## Grouping

ストリームを扱う際に、要素をより構造化された方法でグループ化する必要がある場合があります。Streamモジュールは、これを達成するための2つの便利な関数を提供します：`grouped` と `groupedWithin`。このセクションでは、これらの関数がどのように機能し、いつ使用するかを探ります。

### grouped

`Stream.grouped` 関数は、ストリームの結果を指定されたサイズのチャンクに分割するのに最適です。特に、データをより小さく、管理しやすい部分で扱いたい場合に便利です。

以下は、`Stream.grouped` の使用例です：

```ts twoslash
import { Stream, Effect } from "effect"

const stream = Stream.range(0, 8).pipe(Stream.grouped(3))

Effect.runPromise(Stream.runCollect(stream)).then((chunks) =>
  console.log("%o", chunks)
)
/*
出力:
{
  _id: 'Chunk',
  values: [
    { _id: 'Chunk', values: [ 0, 1, 2, [length]: 3 ] },
    { _id: 'Chunk', values: [ 3, 4, 5, [length]: 3 ] },
    { _id: 'Chunk', values: [ 6, 7, 8, [length]: 3 ] },
    [length]: 3
  ]
}
*/
```

この例では、0から9までの数字のストリームを取り、`Stream.grouped(3)` を使用してサイズ3のチャンクに分割します。

### groupedWithin

`Stream.groupedWithin` 関数は、時間間隔またはチャンクサイズに基づいてイベントをグループ化する柔軟性を提供します。どちらの条件が先に満たされてもグループ化が行われます。これは、時間制約に基づいてデータをグループ化したい場合に特に便利です。

```ts twoslash
import { Stream, Schedule, Effect, Chunk } from "effect"

const stream = Stream.range(0, 9).pipe(
  Stream.repeat(Schedule.spaced("1 second")),
  Stream.groupedWithin(18, "1.5 seconds"),
  Stream.take(3)
)

Effect.runPromise(Stream.runCollect(stream)).then((chunks) =>
  console.log(Chunk.toArray(chunks))
)
/*
出力:
[
  {
    _id: 'Chunk',
    values: [
      0, 1, 2, 3, 4, 5, 6,
      7, 8, 9, 0, 1, 2, 3,
      4, 5, 6, 7
    ]
  },
  {
    _id: 'Chunk',
    values: [
      8, 9, 0, 1, 2,
      3, 4, 5, 6, 7,
      8, 9
    ]
  },
  {
    _id: 'Chunk',
    values: [
      0, 1, 2, 3, 4, 5, 6,
      7, 8, 9, 0, 1, 2, 3,
      4, 5, 6, 7
    ]
  }
]
*/
```

この例では、`Stream.groupedWithin(18, "1.5 seconds")` を使用してデータのチャンクを作成します。グループ化の操作は、18個の要素に達するか、前のチャンクが作成されてから1.5秒が経過したときに行われます。これは、時間に敏感なデータを扱う場合や、チャンクサイズを動的に制御したい場合に特に便利です。

## 連結

ストリーム処理では、複数のストリームの内容を結合したいシナリオが存在します。Streamモジュールは、これを達成するためのいくつかのオペレーターを提供しており、`Stream.concat`、`Stream.concatAll`、および`Stream.flatMap`が含まれます。これらのオペレーターを探求し、効果的に使用する方法を理解しましょう。

### シンプルな連結

`Stream.concat`オペレーターは、2つのストリームを連結するための簡単な方法です。これは、左側のストリームの要素に続いて右側のストリームの要素を発する新しいストリームを返します。これは、2つのストリームを順次結合したい場合に便利です。

`Stream.concat` の使用例を以下に示します：

```ts twoslash
import { Stream, Effect } from "effect"

const s1 = Stream.make(1, 2, 3)
const s2 = Stream.make(4, 5)

const stream = Stream.concat(s1, s2)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ 1, 2, 3, 4, 5 ] }
*/
```

### 複数のストリームの連結

複数のストリームを連結したい場合があります。`Stream.concat`操作を手動でチェーンする代わりに、`Stream.concatAll`を使用してストリームの`Chunk`を連結することができます。

以下はその例です：

```ts twoslash
import { Stream, Effect, Chunk } from "effect"

const s1 = Stream.make(1, 2, 3)
const s2 = Stream.make(4, 5)
const s3 = Stream.make(6, 7, 8)

const stream = Stream.concatAll(Chunk.make(s1, s2, s3))

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{
  _id: 'Chunk',
  values: [
    1, 2, 3, 4,
    5, 6, 7, 8
  ]
}
*/
```

### flatMapを使った高度な連結

`Stream.flatMap`オペレーターを使用すると、ソースストリームの各出力に対して型 `(a: A) => Stream<...>` の関数を適用することで、要素が生成されるストリームを作成できます。これにより、すべての結果が連結されます。

以下に`Stream.flatMap`の使用例を示します：

```ts twoslash
import { Stream, Effect } from "effect"

const stream = Stream.make(1, 2, 3).pipe(
  Stream.flatMap((a) => Stream.repeatValue(a).pipe(Stream.take(4)))
)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{
  _id: 'Chunk',
  values: [
    1, 1, 1, 1, 2,
    2, 2, 2, 3, 3,
    3, 3
  ]
}
*/
```

`flatMap`を並行して実行する必要がある場合は、`concurrency`オプションを使用できます。また、連結の順序が重要でない場合は、`switch`オプションを使用できます。

## マージ

時々、2つのストリームの出力を交互に組み合わせて新しいストリームを作成する必要があります。この場合、`Stream.concat`操作は使用できません。なぜなら、concat操作は最初のストリームが終了するのを待ってから2番目のストリームを消費するからです。したがって、異なるソースから要素を選択する方法が必要です。Effect Streamのmerge操作はこれを実現します。この操作のいくつかのバリエーションについて説明しましょう。

### merge

`Stream.merge`操作は、異なるソースストリームから要素を選択し、それらを単一のストリームにマージすることを可能にします。`Stream.concat`とは異なり、`Stream.merge`は最初のストリームが終了するのを待たずに、両方のストリームから利用可能な要素を交互に取り込みます。

以下に例を示します：

```ts twoslash
import { Schedule, Stream, Effect } from "effect"

const s1 = Stream.make(1, 2, 3).pipe(
  Stream.schedule(Schedule.spaced("100 millis"))
)
const s2 = Stream.make(4, 5, 6).pipe(
  Stream.schedule(Schedule.spaced("200 millis"))
)

const stream = Stream.merge(s1, s2)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ 1, 4, 2, 3, 5, 6 ] }
*/
```

### Termination Strategy

2つのストリームをマージする際には、その終了戦略を考慮する必要があります。各ストリームにはそれぞれの寿命があり、すぐに終了するものもあれば、無期限に続くものもあります。デフォルトでは、`Stream.merge`を使用する場合、結果のストリームは指定された両方のストリームが終了したときにのみ終了します。

しかし、要件に合わせて終了戦略を定義することができます。Streamは`haltStrategy`オプションを使用して4つの異なる終了戦略を提供します：

- `"left"`: 結果のストリームは左側のストリームが終了したときに終了します。
- `"right"`: 結果のストリームは右側のストリームが終了したときに終了します。
- `"both"`: 結果のストリームは両方のストリームが終了したときに終了します。
- `"either"`: 結果のストリームはどちらか一方のストリームが終了したときに終了します。

終了戦略を指定する例を以下に示します：

```ts twoslash
import { Stream, Schedule, Effect } from "effect"

const s1 = Stream.range(1, 5).pipe(
  Stream.schedule(Schedule.spaced("100 millis"))
)
const s2 = Stream.repeatValue(0).pipe(
  Stream.schedule(Schedule.spaced("200 millis"))
)

const stream = Stream.merge(s1, s2, { haltStrategy: "left" })

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{
  _id: 'Chunk',
  values: [
    1, 0, 2, 3,
    0, 4, 5
  ]
}
*/
```

この例では、`haltStrategy: "left"`を使用して、左側のストリーム（`s1`）が終了したときに結果のストリームが終了するようにしています。

### mergeWith

場合によっては、2つのストリームをマージするだけでなく、それらの要素を新しい型に変換して統一したいことがあります。ここで役立つのが`Stream.mergeWith`です。これにより、両方のソースストリームに対して変換関数を指定することができます。

以下に例を示します：

```ts twoslash
import { Schedule, Stream, Effect } from "effect"

const s1 = Stream.make("1", "2", "3").pipe(
  Stream.schedule(Schedule.spaced("100 millis"))
)
const s2 = Stream.make(4.1, 5.3, 6.2).pipe(
  Stream.schedule(Schedule.spaced("200 millis"))
)

const stream = Stream.mergeWith(s1, s2, {
  onSelf: (s) => parseInt(s),
  onOther: (n) => Math.floor(n)
})

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ 1, 4, 2, 3, 5, 6 ] }
*/
```

この例では、`Stream.mergeWith`を使用して、`s1`と`s2`をマージし、`s1`の文字列要素を整数に変換し、`s2`の小数要素を丸めています。

## Interleaving

`Stream.interleave`オペレーターを使用すると、2つのストリームから1つずつ要素を取り出し、新しいインターリーブされたストリームを作成できます。どちらかのストリームが終了すると、残りの値はもう一方のストリームから取り出されます。

以下に例を示します：

```ts twoslash
import { Stream, Effect } from "effect"

const s1 = Stream.make(1, 2, 3)
const s2 = Stream.make(4, 5, 6)

const stream = Stream.interleave(s1, s2)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{ _id: 'Chunk', values: [ 1, 4, 2, 5, 3, 6 ] }
*/
```

より高度なインターリーブロジックのために、`Stream.interleaveWith`は追加の柔軟性を提供します。これは、`boolean`値の第三のストリームを使用してインターリーブロジックを指定することができます。booleanストリームが`true`を出力すると、左側のストリームから要素を選択し、そうでない場合は右側のストリームから要素を選択します。

以下に例を示します：

```ts twoslash
import { Stream, Effect } from "effect"

const s1 = Stream.make(1, 3, 5, 7, 9)
const s2 = Stream.make(2, 4, 6, 8, 10)

const booleanStream = Stream.make(true, false, false).pipe(Stream.forever)

const stream = Stream.interleaveWith(s1, s2, booleanStream)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{
  _id: 'Chunk',
  values: [
    1, 2,  4, 3, 6,
    8, 5, 10, 7, 9
  ]
}
*/
```

この例では、`booleanStream`がどのソースストリームをインターリーブするかを決定します。`true`の場合は`s1`から要素を選び、`false`の場合は`s2`から要素を選びます。

## Interspersing

インタースパースは、ストリームにセパレーターを追加する技術です。これは、ストリーム内のデータをフォーマットしたり構造化したりする際に特に有用です。

### intersperse

`Stream.intersperse`オペレーターを使用すると、ストリームの要素の間に区切り要素を挿入できます。この区切り要素は任意の値にすることができます。元のストリームの各要素のペアの間に追加されます。

以下に例を示します：

```ts twoslash
import { Stream, Effect } from "effect"

const stream = Stream.make(1, 2, 3, 4, 5).pipe(Stream.intersperse(0))

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{
  _id: 'Chunk',
  values: [
    1, 0, 2, 0, 3,
    0, 4, 0, 5
  ]
}
*/
```

この例では、1から5までの数字を持つストリーム`stream`に対して、`Stream.intersperse(0)`を使用してその間にゼロを追加しています。

### intersperseAffixes

より高度なインタースパースのニーズに対しては、`Stream.intersperseAffixes`がより多くの制御を提供します。これにより、ストリームの開始、中間、および終了に異なる接辞を指定することができます。これらの接辞は文字列でも他の任意の値でも構いません。

以下に例を示します：

```ts twoslash
import { Stream, Effect } from "effect"

const stream = Stream.make(1, 2, 3, 4, 5).pipe(
  Stream.intersperseAffixes({
    start: "[",
    middle: "-",
    end: "]"
  })
)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
{
  _id: 'Chunk',
  values: [
    '[', 1,   '-', 2,   '-',
    3,   '-', 4,   '-', 5,
    ']'
  ]
}
*/
```

この例では、`Stream.intersperseAffixes`を使用して、1から5までの数字を角括弧で囲み、ハイフンで区切っています。

## ブロードキャスト

ストリームのブロードキャストは、元のストリームと同じ要素を含む複数のストリームを作成する方法です。この操作により、各要素を同時に複数の下流ストリームに送信することができます。ただし、上流ストリームは`maximumLag`パラメータによって決定される特定の制限までしかイベントを発行できません。この制限に達すると、上流ストリームは最も遅い下流ストリームの速度に合わせて速度を落とします。

次の例でブロードキャストの動作を詳しく見てみましょう。ここでは、数値のストリームを2つの下流ストリームにブロードキャストしています。そのうちの1つはストリーム内の最大数を計算し、もう1つは追加の遅延を伴うログを実行します。上流ストリームは、遅い方のログストリームの速度に基づいて速度を調整します：

```ts twoslash
import { Effect, Stream, Console, Schedule, Fiber } from "effect"

const numbers = Effect.scoped(
  Stream.range(1, 20).pipe(
    Stream.tap((n) => Console.log(`Emit ${n} element before broadcasting`)),
    Stream.broadcast(2, 5),
    Stream.flatMap(([first, second]) =>
      Effect.gen(function* () {
        const fiber1 = yield* Stream.runFold(first, 0, (acc, e) =>
          Math.max(acc, e)
        ).pipe(
          Effect.andThen((max) => Console.log(`Maximum: ${max}`)),
          Effect.fork
        )
        const fiber2 = yield* second.pipe(
          Stream.schedule(Schedule.spaced("1 second")),
          Stream.runForEach((n) =>
            Console.log(`Logging to the Console: ${n}`)
          ),
          Effect.fork
        )
        yield* Fiber.join(fiber1).pipe(
          Effect.zip(Fiber.join(fiber2), { concurrent: true })
        )
      })
    ),
    Stream.runCollect
  )
)

Effect.runPromise(numbers).then(console.log)
/*
出力:
Emit 1 element before broadcasting
Emit 2 element before broadcasting
Emit 3 element before broadcasting
Emit 4 element before broadcasting
Emit 5 element before broadcasting
Emit 6 element before broadcasting
Emit 7 element before broadcasting
Emit 8 element before broadcasting
Emit 9 element before broadcasting
Emit 10 element before broadcasting
Emit 11 element before broadcasting
Logging to the Console: 1
Logging to the Console: 2
Logging to the Console: 3
Logging to the Console: 4
Logging to the Console: 5
Emit 12 element before broadcasting
Emit 13 element before broadcasting
Emit 14 element before broadcasting
Emit 15 element before broadcasting
Emit 16 element before broadcasting
Logging to the Console: 6
Logging to the Console: 7
Logging to the Console: 8
Logging to the Console: 9
Logging to the Console: 10
Emit 17 element before broadcasting
Emit 18 element before broadcasting
Emit 19 element before broadcasting
Emit 20 element before broadcasting
Logging to the Console: 11
Logging to the Console: 12
Logging to the Console: 13
Logging to the Console: 14
Logging to the Console: 15
Maximum: 20
Logging to the Console: 16
Logging to the Console: 17
Logging to the Console: 18
Logging to the Console: 19
Logging to the Console: 20
{ _id: 'Chunk', values: [ undefined ] }
*/
```

## バッファ

Effect streamsはプルベースの方法で動作します。つまり、下流の消費者は上流に減速を知らせる必要なく、自分のペースで要素を要求できます。しかし、生産者と消費者を独立して扱う必要があるシナリオ、特に両者の速度が一致しない場合があります。ここでバッファリングが役立ち、速い生産者と遅い消費者の間の通信を効果的に管理できます。Effect streamsはこれを支援するために組み込みの`Stream.buffer`オペレーターを提供します。

### buffer

`Stream.buffer`オペレーターは、速い生産者が遅い消費者と独立して作業する必要があるシナリオを容易にするために設計されています。これは、要素をキューにバッファリングすることで実現され、消費者が遅れても生産者が作業を続けることができます。`capacity`オプションを使用して最大バッファ容量を指定できます。

例を見てみましょう:

```ts twoslash
import { Stream, Console, Schedule, Effect } from "effect"

const stream = Stream.range(1, 10).pipe(
  Stream.tap((n) => Console.log(`before buffering: ${n}`)),
  Stream.buffer({ capacity: 4 }),
  Stream.tap((n) => Console.log(`after buffering: ${n}`)),
  Stream.schedule(Schedule.spaced("5 seconds"))
)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力:
before buffering: 1
before buffering: 2
before buffering: 3
before buffering: 4
before buffering: 5
before buffering: 6
after buffering: 1
after buffering: 2
before buffering: 7
after buffering: 3
before buffering: 8
after buffering: 4
before buffering: 9
after buffering: 5
before buffering: 10
...
*/
```

この例では、1から11までの数字のストリームを作成します。`Stream.buffer({ capacity: 4 })`を使用して、一度に最大4つの要素をバッファリングします。ご覧のとおり、`Stream.tap`オペレーターを使用して、バッファリングの前後に各要素をログに記録できます。また、メッセージの生成と消費の遅延を示すために、各エミッションの間に5秒の遅延を導入しています。

必要な基礎となるキューの種類に基づいて、さまざまなバッファリングオプションを選択できます：

- Bounded Queue: `{ capacity: number }`
- Unbounded Queue: `{ capacity: "unbounded" }`
- Sliding Queue: `{ capacity: number, strategy: "sliding" }`
- Dropping Queue: `{ capacity: number, strategy: "dropping" }`

## Debouncing

プログラミングにおけるデバウンシングは、関数が頻繁に実行されすぎないようにするために使用されます。
これは特に、ストリームが急速に連続して値を発行するが、活動の一時停止後にのみ反応する必要があるシナリオで非常に有用です。

Effect ライブラリの `Stream.debounce` 関数は、ストリーム値の発行を遅延させることでこれを例示しています。
新しい値が発生せずに指定された期間が経過するのを待ってから、最新の値を発行します。
この待機期間中に新しい値が到着した場合、現在の値は破棄され、タイマーは新しい値でリセットされます。

```ts twoslash
import { Stream, Effect } from "effect"

let last = Date.now()
const log = (message: string) =>
  Effect.sync(() => {
    const end = Date.now()
    console.log(`${message} after ${end - last}ms`)
    last = end
  })

const stream = Stream.make(1, 2, 3).pipe(
  Stream.concat(
    Stream.fromEffect(Effect.sleep("200 millis").pipe(Effect.as(4))) // 200ミリ秒後に4を発行
  ),
  Stream.concat(Stream.make(5, 6)), // より速いペースで値を続ける
  Stream.concat(
    Stream.fromEffect(Effect.sleep("150 millis").pipe(Effect.as(7))) // 150ミリ秒後に7を発行
  ),
  Stream.concat(Stream.make(8)),
  Stream.tap((n) => log(`Recoived: ${n}`)),
  Stream.debounce("100 millis"), // 少なくとも100ミリ秒の間隔後にのみ値を発行
  Stream.tap((n) => log(`> Emitted ${n}`))
)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力の例:
Received 1 after 5ms
Received 2 after 2ms
Received 3 after 0ms
> Emitted 3 after 104ms
Received 4 after 99ms
Received 5 after 1ms
Received 6 after 0ms
> Emitted 6 after 101ms
Received 7 after 50ms
Received 8 after 1ms
> Emitted 8 after 101ms
{ _id: 'Chunk', values: [ 3, 6, 8 ] }
*/
```

## スロットリング

スロットリングは、ストリームから要素が発行される速度を制御するために使用される技術です。
これは、データ出力の一定のペースを維持するのに役立ち、特にデータ処理が一貫したレートで行われる必要があるシナリオで非常に価値があります。

`Stream.throttle` 関数は、[トークンバケットアルゴリズム](https://en.wikipedia.org/wiki/Token_bucket)を利用して、このストリームのチャンクの速度を制御します。

**スロットル設定の例**

```ts
Stream.throttle({
  cost: () => 1,
  duration: "100 millis",
  units: 1
})
```

この設定では：

- 処理される各チャンクは1トークンを使用します（`cost = () => 1`）。
- トークンは100ミリ秒ごとに1トークンの割合で補充されます（`duration: "100 millis"`、`units: 1`）。

<Info>
  スロットリングは個々の要素ではなくチャンクに対して動作することに注意することが重要です。`cost`関数は各チャンクのトークンコストを決定します。
</Info>

### シェイプ戦略（デフォルト）

「シェイプ」戦略は、指定された帯域幅の制約に適合するまでチャンクの発行を遅らせることでデータフローを調整します。
この戦略は、データのスループットが定義された制限を超えないようにし、安定した制御されたデータ発行を可能にします。

```ts twoslash
import { Stream, Effect, Schedule, Chunk } from "effect"

let last = Date.now()
const log = (message: string) =>
  Effect.sync(() => {
    const end = Date.now()
    console.log(`${message} after ${end - last}ms`)
    last = end
  })

const stream = Stream.fromSchedule(Schedule.spaced("50 millis")).pipe(
  Stream.take(6),
  Stream.tap((n) => log(`Received ${n}`)),
  Stream.throttle({
    cost: Chunk.size,
    duration: "100 millis",
    units: 1
  }),
  Stream.tap((n) => log(`> Emitted ${n}`))
)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力の例:
Received 0 after 56ms
> Emitted 0 after 0ms
Received 1 after 52ms
> Emitted 1 after 48ms
Received 2 after 52ms
> Emitted 2 after 49ms
Received 3 after 52ms
> Emitted 3 after 48ms
Received 4 after 52ms
> Emitted 4 after 47ms
Received 5 after 52ms
> Emitted 5 after 49ms
{ _id: 'Chunk', values: [ 0, 1, 2, 3, 4, 5 ] }
*/
```

### 強制戦略

「強制」戦略は、帯域幅の制約を超えるチャンクを破棄することで、データフローを厳密に規制します。

```ts twoslash
import { Stream, Effect, Schedule, Chunk } from "effect"

let last = Date.now()
const log = (message: string) =>
  Effect.sync(() => {
    const end = Date.now()
    console.log(`${message} after ${end - last}ms`)
    last = end
  })

const stream = Stream.make(1, 2, 3, 4, 5, 6).pipe(
  Stream.schedule(Schedule.exponential("100 millis")),
  Stream.tap((n) => log(`Received ${n}`)),
  Stream.throttle({
    cost: Chunk.size,
    duration: "1 second",
    units: 1,
    strategy: "enforce"
  }),
  Stream.tap((n) => log(`> Emitted ${n}`))
)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力の例:
Received 1 after 106ms
> Emitted 1 after 1ms
Received 2 after 200ms
Received 3 after 402ms
Received 4 after 801ms
> Emitted 4 after 1ms
Received 5 after 1601ms
> Emitted 5 after 1ms
Received 6 after 3201ms
> Emitted 6 after 0ms
{ _id: 'Chunk', values: [ 1, 4, 5, 6 ] }
*/
```

### バーストオプション

`Stream.throttle`関数は、設定されたレート制限を超えて一時的にデータスループットを増加させることができるバーストオプションを提供します。
このオプションは、バースト機能を有効にするために0より大きい値に設定されます（デフォルトは0で、バーストサポートがないことを示します）。
バースト容量は、トークンバケットに追加のトークンを提供し、データのバーストが発生したときにストリームが一時的に設定されたレートを超えることを可能にします。

```ts twoslash
import { Effect, Schedule, Stream, Chunk } from "effect"

let last = Date.now()
const log = (message: string) =>
  Effect.sync(() => {
    const end = Date.now()
    console.log(`${message} after ${end - last}ms`)
    last = end
  })

const stream = Stream.fromSchedule(Schedule.spaced("10 millis")).pipe(
  Stream.take(20),
  Stream.tap((n) => log(`Received ${n}`)),
  Stream.throttle({
    cost: Chunk.size,
    duration: "200 millis",
    units: 5,
    strategy: "enforce",
    burst: 2
  }),
  Stream.tap((n) => log(`> Emitted ${n}`))
)

Effect.runPromise(Stream.runCollect(stream)).then(console.log)
/*
出力の例:
Received 0 after 16ms
> Emitted 0 after 0ms
Received 1 after 12ms
> Emitted 1 after 0ms
Received 2 after 11ms
> Emitted 2 after 0ms
Received 3 after 11ms
> Emitted 3 after 0ms
Received 4 after 11ms
> Emitted 4 after 1ms
Received 5 after 11ms
> Emitted 5 after 0ms
Received 6 after 12ms
> Emitted 6 after 0ms
Received 7 after 11ms
Received 8 after 12ms
Received 9 after 11ms
Received 10 after 11ms
> Emitted 10 after 0ms
Received 11 after 11ms
Received 12 after 11ms
Received 13 after 12ms
> Emitted 13 after 0ms
Received 14 after 11ms
Received 15 after 12ms
Received 16 after 11ms
Received 17 after 11ms
> Emitted 17 after 0ms
Received 18 after 12ms
Received 19 after 10ms
{
  _id: 'Chunk',
  values: [
    0, 1,  2,  3,  4,
    5, 6, 10, 13, 17
  ]
}
*/
```

このセットアップでは、ストリームは5つのトークンを含むバケットから始まり、最初の5つのチャンクを即座に発行することができます。
追加の2つのバースト容量により、一時的にさらなる発行が可能となり、後続のデータをより柔軟に処理できます。
時間の経過とともに、スロットル設定に従ってバケットが補充されると、追加の要素が発行され、バースト機能が不均一なデータフローを効果的に管理できることを示しています。
